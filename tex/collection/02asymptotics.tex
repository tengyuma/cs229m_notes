% reset section counter
\setcounter{section}{0}

%\metadata{lecture ID}{Your names}{date}
\metadata{2}{Alexander Ke and Trenton Chang}{Jan 13th, 2021}

This chapter briefly reviews the classical asymptotic results and techniques, which assume the number of training examples $n$ goes to infinity while all other (hyper-)parameters are treated as constants. It is not clear whether these results and techniques are still applicable to modern machine learning, where the number of parameters can often be larger than the number of examples. None of the later chapters depend on this chapter, so readers who are only interested in deep learning can feel free to skip it.  

Nevertheless, I still include these results in this text because the key ideas of using Taylor expansion and law of large numbers are so elegant and foundational that most machine learning theorists should probably be aware of them. 
The rest of the monograph will work in the non-asymptotic setting and one of the key technical difference will be that Taylor expansion cannot be applied and that the concentration inequalities need to be strengthened. 
Due to limited space, we will focus on the core ideas at the expense of some mathematical rigor. The conceptual ideas and techniques of this chapter is self-contained, whereas a fully rigorous treatment of these concepts require additional mathematical language that is beyond the scope of this monograph. We refer the readers to~\citep{vaart_1998} for more in-depth presentation of this line of work. 




%In this chapter, we use an asymptotic approach (i.e. assuming number of training samples $n \to \infty$) to achieve a bound on the ERM. 
%We then instantiate these results to the case where the loss function is the maximum likelihood  and discuss the limitations of asymptotics. 
%(In future chapters we will assume finite $n$ and provide a non-asymptotic analysis.)

\sec{Asymptotics of empirical risk minimization}

The goal of the asymptotic analysis of ERM is to bound from above the excess risk in the following form:
\al{
    L(\hat{\theta}) - \inf_{\theta \in \Theta} L(\theta) \leq \frac{c}{n} + o\left(\frac{1}{n}\right)\,. 
    \label{lec1:eqn:erm-bound}
}
Here $c$ is a problem-dependent constant that is independent of $n$, and the $o(\cdot)$ notation hides all dependencies except for $n$. The equation above shows that as the number of training examples $n$ increases, the excess risk of ERM decreases at the rate of $\frac{1}{n}$.

Let $\{(x^{(1)},y^{(1)}), \cdots, (x^{(n)},y^{(n)})\}$ be the training data and let $\cH = \{ h_\theta: \theta \in \R^p \}$ be the parameterized family of hypothesis functions. Let $\hat{\theta}$ be the empirical risk minimizer as defined in~\Cref{lec1:eqn:erm:theta}. Let $\theta^{*}$ be the minimizer of the population risk $L$ (i.e., $\theta^{*} = \argmin_\theta L(\theta)$, )which is assumed to be unique. The theorem below characterize the excess risk $L(\hat{\theta}) - L(\theta^{*})$, which is a random variable (where the randomness comes from the training dataset). 

\begin{theorem}[Informally stated] \label{lec1:thm:asymp}
Assume that (a) the consistency of the ERM estimator $\hat{\theta}$ in the sense that $\hat{\theta}  \overset{p}{\to} \theta^{*}$ as $n \to \infty$, (b) the Hessian of the population loss at $\theta^*$, $\nabla^{2}L(\theta^{*})$, is full rank, and  (c) other appropriate regularity conditions hold.\footnote{$X_n \overset{p}{\to} X$ implies that for all $\epsilon > 0$, $\bbP \left (\norm{X_n - X} > \epsilon \right ) \to 0$, while $X_n \overset{d}{\to} X$ implies that $\bbP(X_n \leq t) \to \bbP(X \leq t)$ at all points $t$ for which $\bbP(X \leq t)$ is continuous. These two notions of convergence are known as convergence in probability and convergence in distribution, respectively. These concepts are not essential to this course, but additional information can be found by reading the Wikipedia \href{https://en.wikipedia.org/wiki/Convergence_of_random_variables}{article} on convergence of random variables.} 
Then,
\begin{enumerate}
    \item The estimated model $\hat{\theta}$ converges to the $\theta^*$ with a $1/\sqrt{n}$ rate in the sense that $\sqrt{n} (\hat{\theta} - \theta^{*}) = O_P(1)$, that is, for every $\epsilon > 0$, there is an $M$ such that $\forall n, \bbP (\| \sqrt{n} (\hat{\theta} - \theta^{*}) \|_2 > M) \le \epsilon$.\footnote{In other words, the sequence of random variables $\{ \sqrt{n} (\hat{\theta} - \theta^{*}) \}$ indexed by $n$ is ``bounded in probability" . } 
    \item  The scaled parameter error $\sqrt{n}(\hat{\theta}-\theta^{*})$ has asymptotic normality distribution in the sense that as $n\rightarrow \infty$, 
    \al{\sqrt{n}(\hat{\theta}-\theta^{*}) \overset{d}{\to} \mathcal{N} \left(0, (\nabla^{2}L(\theta^{*}))^{-1}\Cov(\nabla \ell((x,y), \theta^*)) (\nabla^{2}L(\theta^{*}))^{-1} \right) \,.}
     \item The excess loss decays with an $1/n$ rate
    \al{n (L(\hat{\theta}) - L(\theta^{*})) = O_P(1)\,.
    	\label{eqn:3}
    }
     Moreover, 
     \begin{align}
     \lim_{n \to \infty} \Exp \left[ n (L(\hat \theta) - L(\theta^*)) \right] = \frac12 \tr\left( \nabla^2 L(\theta^*)^{-1} \Cov(\nabla \ell ((x, y), \theta^*) \right)\,.\label{eqn:4}
     \end{align}
    \item The scaled excess loss has a $\chi^2$ distribution: 
    \begin{align}
    n (L(\hat{\theta}) - L(\theta^{*})) \overset{d}{\to} \frac{1}{2} ||S||_{2}^{2} \,.
    \end{align}
    where $S \sim \mathcal{N} \left(0, (\nabla^{2}L(\theta^{*}))^{-1/2}\Cov(\nabla \ell((x,y), \theta^*)) (\nabla^{2}L(\theta^{*}))^{-1/2}\right)$.
\end{enumerate}
\end{theorem}
%\textbf{Remark:} In the theorem above, Parts 1 and 3 only show the rate or order of convergence, while Parts 2 and 4 define the limiting distribution for the random variables.
%is a powerful conclusion because once we know that $\sqrt{n}(\hat \theta  - \theta^*)$ is (asymptotically) Gaussian, we can easily work out the distribution of the excess risk. 
%If we believe in our assumptions and $n$ is large enough such that we can assume $n \to \infty$, this allows us to analytically determine quantities of interest in almost any scenario (for example, if our test distribution changes). 

The key takeaway is that our parameter error $\hat{\theta} - \theta^*$ decreases on the order of $1/\sqrt{n}$ and the excess risk decreases on the order of $1/n$. We note that the twice-differentiable loss function $L$ plays a crucial role in the rate here---e.g., if the loss for a regression problem is $|\hat{y}-y|$ instead of the squared loss, the excess rate will not have a $1/n$ rate. 

Theorem \ref{lec1:thm:asymp} is powerful because the characterization of the distribution of  $\sqrt{n}(\hat \theta  - \theta^*)$ can lead us to almost any property of $\hat{\theta}$ of interest. For example, in principle, one can characterize the expected loss of the estimator $\hat{\theta}$ on a test distribution different from the distribution $P$. On the other hand, the theorem requires taking the limit as $n$ goes to infinity while ignoring the dependencies on other problem parameters (such as dimension). This significantly limits the applicability of the theorem in modern machine learning settings (see Section~\ref{sec:limit-asymp} for more discussion). 
%While we will not discuss the regularity assumptions in Theorem~\ref{lec1:thm:asymp} in great detail, we note that the assumption that $L$ is twice differentiable is crucial. 

\subsec{Key proof ideas} 

We will sketch a proof Theorem \ref{lec1:thm:asymp} by applying the following two key ideas. 
\begin{enumerate}
    \item[1] \textbf{Taylor expansion.} We will derive a formula for $\hat{\theta}$ and the excess risk by Taylor-expanding the empirical loss $\nabla \hatL(\theta)$ (and its gradient )around the reference point $\theta^{*}$.
    \item[2] \textbf{Law of large number and central limit theorem.} We will simplify and characterize various empirical quantities, e.g.,  $\hatL(\theta)$ and $\hatL^2(\theta)$ by the law of large numbers and central limit theorems. For exmaple, we will use the facts that $\hatL(\theta) \overset{p}{\to} L(\theta)$, $\nabla\hatL(\theta) \overset{p}{\to} \nabla L(\theta)$   and  $\nabla^{2}\hatL(\theta) \overset{p}{\to} \nabla^{2} L(\theta)$ as $n \to \infty$, and that $\nabla \hatL(\theta)-\nabla L(\theta)$ is asymptotically normal. 
\end{enumerate}
 
To prepare us with more detail, we first state the the central limit theorem for a sum of i.i.d. random variables.

\begin{theorem}[Central Limit Theorem] \label{lec1:thm:CLT}
Let $X_1, \cdots, X_n$ be i.i.d. $d$-dimensional random variables and $\widehat{X}=\frac{1}{n} \sum_{i=1}^{n} X_i$ and the covariance matrix $\Sigma = \Exp[X_iX_i^\top]\in \R^{d\times d}$ is finite. Then, as $n \to \infty$, we have
\begin{enumerate}
    \item $\widehat{X} \overset{p}{\to} \Exp[X]$, and
    \item $\sqrt{n} (\widehat{X}-\Exp[X]) \overset{d}{\to} \mathcal{N}(0,\Sigma)$. %In particular, $\sqrt{n} (\widehat{X}-\Exp[X]) = O_P(1)$.
\end{enumerate}
\end{theorem}

We also state a lemma that asserts the linear transformation of a Gaussian random variable is still Gaussian and computes its covariance. %The second part claims that quadratic form of Gaussian random variable has a $\chi^2$ distribution.  
\begin{lemma}\label{lec1:lem:dist}
%\quad\quad
%    \begin{enumerate}
If $Z \sim N(0, \Sigma)$ and $A$ is a deterministic matrix, then $AZ \sim N(0, A \Sigma A^\top)$. \tnote{todo second part of the old lemma}
%\subsec{Main proof}        
%        \item If $Z \sim N(0, \Sigma^{-1})$ and $Z \in \bbR^p$, then $Z^\top \Sigma Z \sim \chi^2(p)$, where $\sim \chi^2(p)$ is the chi-squared distribution with $p$ degrees of freedom.
%    \end{enumerate}
\end{lemma}
With these preparations, we will sketch a proof for parts 1 and 2 of Theorem~\ref{lec1:thm:asymp}. 

By definition, the gradient of the empirical risk evaluated at the empirical risk minimizer, that is, $\nabla \hatL(\hat{\theta})$, is equal to $0$. From the Taylor expansion of $\nabla \hatL$ around $\theta^*$, we have that 
\begin{align}
    0 = \nabla \hatL(\hat{\theta}) = \nabla \hatL(\theta^*) + \nabla^2 \hatL(\theta^*)(\hat{\theta} - \theta^*) + O(\|\hat{\theta} - \theta^*\|^2_2)\perm\text{\footnotemark}
\end{align}

Rearranging the equation above,\footnotetext{Technically, the big-O notation here and in the sequel should be $O_P(\cdot)$ because $\hat{\theta}$ is a random variable. However, we omit this distinction in this proof sketch.} gives a solution for $\hat{\theta}-\theta^*$, 
\al{
 \hat{\theta}-\theta^{*} = -(\nabla^{2}\hatL(\theta^{*}))^{-1} \nabla \hatL(\theta^{*}) + O(||\hat{\theta}-\theta^{*}||_{2}^{2}). \label{lec1:eqn:branch}} 

Multiplying by $\sqrt{n}$ on both sides (so that we deal with quantities on the constant order), we have
 \al{
\sqrt{n} (\hat{\theta}-\theta^{*}) &= -(\nabla^{2}\hatL(\theta^{*}))^{-1} \sqrt{n} (\nabla \hatL(\theta^{*})) + O(\sqrt{n} ||\hat{\theta}-\theta^{*}||_{2}^{2}) \\
&\approx -(\nabla^{2}\hatL(\theta^{*}))^{-1} \sqrt{n} (\nabla \hatL(\theta^{*})). \label{lec1:eqn:interm}}

 
Applying the Central Limit Theorem (Theorem~\ref{lec1:thm:CLT}) using $X_i = \nabla \ell ((x^{(i)}, y^{(i)}), \theta^*)$ and $\widehat{X} = \nabla \hatL(\theta^*)$, and noticing that $\Exp[\nabla \hatL(\theta^{*})] = \nabla L(\theta^{*})$, we have
$\sqrt{n} (\nabla \hatL(\theta^{*}) - \nabla L(\theta^{*})) \overset{d}{\to} \mathcal{N}(0,\Cov(\nabla \ell((x, y), \theta^{*}))).$ 
 
Note that $\nabla L(\theta^{*}) = 0$ because $\theta^{*}$ is the minimizer of  $L$. Thus, we have \al{\sqrt{n} \cdot\nabla \hatL(\theta^{*}) \overset{d}{\to} \mathcal{N}(0,\Cov(\nabla \ell((x, y), \theta^{*})))\perm}
By the law of large numbers, we have $\nabla^2 \hatL(\theta^*) \stackrel{p}{\rightarrow} \nabla^2 L(\theta^*)$. We use these results to replace the empirical quantity in \Cref{lec1:eqn:interm} by the population quantity (technically this is an application of Slutsky's theorem), we have
\al{
\sqrt{n} (\hat{\theta}-\theta^{*}) &\overset{d}{\to} \nabla^{2}L(\theta^{*})^{-1} \mathcal{N}(0,\Cov(\nabla \ell((x,y),\theta^{*}))) \\
&\stackrel{d}{=} \mathcal{N} \left( 0,\nabla^{2}L(\theta^{*})^{-1}\Cov(\nabla \ell((x,y), \theta^{*})) \nabla^{2}L(\theta^{*})^{-1} \right),
}
where the second step is due to Lemma~\ref{lec1:lem:dist}. This proves Part 2 of Theorem~\ref{lec1:thm:asymp}.

Part 1 follows directly from Part 2 by the fact a sequence of random variables that converges to a fixed Gaussian distribution is also bounded in probability.

We now turn to proving Parts 3 and 4 of Theorem~\ref{lec1:thm:asymp} which uses Part 2. A Taylor expansion of $L$ at the reference point $\theta^*$ gives
\begin{equation}
L(\hat \theta) = L(\theta^*) 
+ \langle \nabla L(\theta^*), \hat \theta - \theta^* \rangle 
+ \frac12 \langle \hat \theta - \theta^*, \nabla^2 L(\theta^*) (\hat \theta - \theta^*) \rangle + o(\|\hat \theta - \theta^*\|_2^2).
\end{equation}
Since $\theta^*$ is the minimizer of the population loss $L$, we have $\nabla L(\theta^*) = 0$ and the linear term $\langle \nabla L(\theta^*), \hat \theta - \theta^* \rangle$ is equal to 0. Rearranging and multiplying by $n$, we can write
\begin{align}
n (L(\hat \theta) - L(\theta^*)) &= \frac{n}{2} \langle \hat \theta - \theta^*, \nabla^2 L(\theta^*) (\hat \theta - \theta^*) \rangle + o(\|\hat \theta - \theta^*\|_2^2) \\
&\approx \frac12 \langle \sqrt n(\hat \theta - \theta^*), \nabla^2 L(\theta^*) \sqrt n (\hat \theta - \theta^*) \rangle \\
&= \frac12 \left\|\nabla^2 L(\theta^*)^{1/2} \sqrt n(\hat \theta - \theta^*) \right\|_2^2,
\end{align}
where the last equality follows from the fact that for any vector $v$ and positive semi-definite matrix $A$ of appropriate dimensions, the inner product $\langle v, Av\rangle = v^\top Av = \lVert A^{1/2}v \rVert_2^2$. Let $S = \nabla^2 L(\theta^*)^{1/2} \sqrt n(\hat \theta - \theta^*)$, i.e., the random vector inside the norm. By Part 2, we know the asymptotic distribution of $\sqrt n(\hat \theta - \theta^*)$ is Gaussian, and by Lemma~\ref{lec1:lem:dist} we know $S$ also has a Gaussian distribution: 
\begin{align}
    S %&\sim \nabla^2 L(\theta^*)^{1/2} \cdot \cN \left(0, \nabla^2 L(\theta^*)^{-1} \Cov(\nabla \ell ((x, y), \theta^*)) \nabla^2 L(\theta^*)^{-1} \right) \\
    &\stackrel{d}{=} \cN \left(0, \nabla^2 L(\theta^*)^{-1/2} \Cov(\nabla \ell ((x, y), \theta^*)) \nabla^2 L(\theta^*)^{-1/2} \right).
\end{align}
This proves Part 4, and Part 3, \Cref{eqn:3} follows directly from the definition of the $O_P$ notation. 

Finally, we derive \Cref{eqn:4} by using the fact that the trace operator is invariant under cyclic permutations,  that $\Exp [S] = 0$, and some regularity conditions,
\begin{align}
    \lim_{n \to \infty} \Exp \left[ n (L(\hat \theta) - L(\theta^*)) \right] &= \frac12 \Exp\left[ \|S\|_2^2 \right] = \frac12 \Exp \left[ \tr(S^\top S) \right] \\
    &= \frac12 \Exp \left[ \tr(S S^\top) \right]  = \frac12 \tr \left(\Exp[S S^\top] \right) \\
    &= \frac12 \tr \left( \Cov(S) \right) \\
    &= \frac12 \tr\left( \nabla^2 L(\theta^*)^{-1} \Cov(\nabla \ell ((x, y), \theta^*)) \right).
\end{align}

\subsec{Well-specified case}

Theorem \ref{lec1:thm:asymp} is quite general without any assumptions of a probabilistic model of the data distribution $P$. In many applications, we assume a probabilistic model of our data and use the log-likelihood as the loss function. This is often referred to as the well-specified case in this context, and it allows some simplification of the conclusions of Theorem~\ref{lec1:thm:asymp} with nice interpretations. 


Formally, suppose that we have a family of probability distributions $P_\theta$, parameterized by $\theta \in \Theta$. We assume the data distribution $P$ belongs to this family, that is, there exists $\theta_*$ such that $P = P_{\theta_*}$. This is known as the well-specified case. Theorem \ref{lec1:thm:asymp} implies the following Theorem \ref{lec2:thm:applied} as a direct corollary.

\begin{theorem}
\label{lec2:thm:applied}
    In addition to the assumptions of Theorem~\ref{lec1:thm:asymp}, suppose there exists a parametric model $P(y \mid x; \theta)$, $\theta \in \Theta$, such that $\{ y\sp{i} \mid x\sp{i} \}_{i=1}^n \sim P( y\sp{i} \mid x\sp{i} ; \theta_*)$ for some $\theta_* \in \Theta$. Assume that we perform maximum likelihood estimation (MLE), i.e., our loss function is the negative log-likelihood $\ell((x\sp{i}, y\sp{i}), \theta) = - \log P( y\sp{i} \mid x\sp{i} ; \theta)$. As before, let $\hat\theta$ and $\theta^*$ denote the minimizers of empirical loss and population loss, respectively. Then, we have
    \al{
    \label{lec2:eqn:applied1}
        \theta^* = \theta_*,
    }
    \al{
    \label{lec2:eqn:applied2}
        \Exp \left[ \nabla \ell ((x, y), \theta^*) \right] = 0,
    }
    \al{
    \label{lec2:eqn:applied3}
        \Cov \left( \nabla \ell ((x, y), \theta^*) \right) = \nabla^2 L(\theta^*), \text{ and}
    }
    \al{
    \label{lec2:eqn:applied4}
        \sqrt n (\hat \theta - \theta^*) \overset d \to \cN (0, \nabla^2 L(\theta^*)^{-1}).
    }
\end{theorem}

\textbf{Remark 1:} You may also have seen \eqref{lec2:eqn:applied4} in the following form: under the maximum likelihood estimation (MLE) paradigm, the MLE is asymptotically efficient as it achieves the Cramer-Rao lower bound. That is, the parameter error of the MLE estimate converges in distribution to $\mathcal{N}(0, \mathcal{I}(\theta)^{-1})$, where $\mathcal{I}(\theta)$ is the Fisher information matrix (in this case, equivalent to the risk Hessian $\nabla^2 L(\theta^*)$)~\cite{rice2006mathematical}.

\textbf{Remark 2:} \eqref{lec2:eqn:applied3} is also known as Bartlett's identity~\cite{percynotes}.

Although the proofs were not presented in live lecture, we include them here.

\begin{proof}
From the definition of the population loss,
\begin{align}
    L(\theta) &= \Exp \left[ \ell((x\sp{i}, y\sp{i}), \theta) \right]\\
    &= \Exp \left[ - \log P(y \mid x; \theta) \right] \\
    &= \Exp \left[ - \log P(y \mid x; \theta) + \log P(y \mid x; \theta_*) \right] + \Exp \left[ - \log P(y \mid x; \theta_*) \right] \\
    &= \Exp \left[ \log \frac{P(y \mid x; \theta_*)}{P(y \mid x; \theta)} \right] + \Exp \left[ - \log P(y \mid x; \theta_*) \right].
\end{align}
Notice that the second term is a constant which we will express as $\cH(y \mid x; \theta_*)$. We expand the first term using the tower rule (or law of total expectation):
\begin{align}
    L(\theta) &= \Exp \left[ \Exp \left[ \log \frac{P(y \mid x; \theta_*)}{P(y \mid x; \theta)} \biggr\vert x \right] \right] + \cH(y \mid x; \theta_*).
\end{align}
The term in the expectation is just the KL divergence between the two probabilities, so 
\begin{align}
    L(\theta) &= \Exp \left[ \KL \left( y \mid x; \theta_* \| y \mid x; \theta \right) \right] + \cH(y \mid x; \theta_*) \\
    &\geq \cH(y \mid x; \theta_*),
\end{align}
since KL divergence is always non-negative. Since $\theta_*$ makes the KL divergence term 0, it minimizes $L(\theta)$ and so $\theta_* \in \argmin_\theta L(\theta)$. However, the minimizer of $L(\theta)$ is unique because of consistency, so  we must have $\argmin_\theta L(\theta) = \theta^*$ which proves (\ref{lec2:eqn:applied1}).

For \eqref{lec2:eqn:applied2}, recall $\nabla L(\theta^*) = 0$, so we have
\begin{equation}
0 = \nabla L(\theta^*) = \nabla \Exp \left[ \ell((x\sp{i}, y\sp{i}), \theta^*) \right] = \Exp \left[ \nabla \ell((x\sp{i}, y\sp{i}), \theta^*) \right],
\end{equation}
where we can switch the gradient and expectation under some regularity conditions.

To prove \eqref{lec2:eqn:applied3}, we first expand the RHS using the definition of covariance and express the marginal distributions as integrals:
\begin{align}
    \Cov \left( \nabla \ell ((x, y), \theta^*) \right) &= \Exp \left[ \nabla \ell ((x, y), \theta^*) \nabla \ell ((x, y), \theta^*)^\top \right] \\
    &= \int P(x) \left( \int P(y \mid x; \theta^*) \nabla \log P( y\sp{i} \mid x\sp{i} ; \theta^*) \nabla \log P( y\sp{i} \mid x\sp{i} ; \theta^*)^\top dy \right) dx \\
    &= \int P(x) \left( \int \frac{\nabla P(y \mid x; \theta^*) \nabla P(y \mid x; \theta^*)^\top}{P(y \mid x; \theta^*)}dy \right) dx.
\end{align}
Now we expand the LHS using the definition of the population loss and differentiate repeatedly:
\begin{align}
    \nabla^2 L(\theta^*) &= \Exp \left[- \nabla^2 \log P(y \mid x; \theta^*) \right] \\
    &= \int P(x) \left( \int - \nabla^2 P(y \mid x; \theta^*) + \frac{\nabla P(y \mid x; \theta^*) \nabla P(y \mid x; \theta^*)^\top}{P(y \mid x; \theta^*)}dy  \right) dx.
\end{align}
Note that we can express 
\begin{equation} \int \nabla^2 P(y \mid x; \theta^*) dy = \nabla^2 \int P(y \mid x; \theta^*) dy = \nabla 1  = 0 \end{equation}
so we find
\begin{equation} \nabla^2 L(\theta^*) = \int P(x) \left( \int \frac{\nabla P(y \mid x; \theta^*) \nabla P(y \mid x; \theta^*)^\top}{P(y \mid x; \theta^*)}dy \right) dx = \Cov \left( \nabla \ell ((x, y), \theta^*) \right). \end{equation}

Finally, \eqref{lec2:eqn:applied4} follows directly from Part 2 of Theorem~\ref{lec1:thm:asymp} and \eqref{lec2:eqn:applied3}.
\end{proof}

Using similar logic to our proof of Part 4 and 5 of Theorem~\ref{lec1:thm:asymp}, we can see that $n (L(\hat \theta) - L(\theta^*)) \overset d \to \frac12 \|S\|_2^2$ where $S \sim N(0, I)$. Since a chi-squared distribution with $p$ degrees of freedom is defined as a sum of the squares of $p$ independent standard normals, it quickly follows that $2n (L(\hat \theta) - L(\theta^*)) \sim  \chi^2(p)$, where $\theta \in \R^p$ and $n \to \infty$. We can thus characterize the excess risk in this case using the propertes of a chi-squared distribution:

\al{
    \lim_{n \to \infty} \Exp \left[ L(\hat \theta) - L(\theta^*) \right] = \frac{p}{2n}.
}

\sec{Limitations of asymptotic analysis}\label{sec:limit-asymp}

One limitation of asymptotic analysis is that our bounds often obscure dependencies on higher order terms. As an example, suppose we have a bound of the form
	\al{
		\frac{p}{2n} + o\left(\frac{1}{n}\right).
		\label{lec2:eqn:spicy_bound}
	}
(Here $o(\cdot)$ treats the parameter $p$ as a constant as $n$ goes to infinity.) 
We have no idea how large $n$ needs to be for asymptotic bounds to be ``reasonable." Compare two possible versions of \eqref{lec2:eqn:spicy_bound}: 
\begin{align}
    \frac{p}{2n} + \frac{1}{n^2} \quad \text{vs.} \quad \frac{p}{2n} + \frac{p^{100}}{n^2}.
\end{align}
Asymptotic analysis treats both of these bounds as the same, hiding the polynomial dependence on $p$ in the second bound. Clearly, the second bound is significantly more data-intensive than the first: we would need $n > p^{50}$ for $\frac{p^{100}}{n^2}$ to be less than one. Since $p$ represents the dimensionality of the data, this may be an unreasonable assumption.

This is where non-asymptotic analysis can be helpful. Whereas asymptotic analysis uses large-sample theorems such as the central limit theorem and the law of large numbers to provide convergence guarantees, non-asymptotic analysis relies on concentration inequalities to develop alternative techniques for reasoning about the performance of learning algorithms.

